val spark = org.apache.spark.sql.SparkSession.builder.getOrCreate

val test = spark.read.json("yelp")
val temp = test.select($"businesses")
val tmp = temp.select(explode($"businesses").as("flat_business"))
val tmp1 = tmp.select($"flat_business.phone", $"flat_business.review_count", $"flat_business.rating", $"flat_business.price",$"flat_business.id", $"flat_business.image_url")

val test1 = sc.wholeTextFiles("noisecountresult")
val noise = test1.map(_._2).flatMap(_.split("\n"))
val noise1 = noise.map(line => line.substring(1, line.length-1)).map(_.split(","))

import org.apache.spark.sql.{Row, SparkSession, }
import org.apache.spark.sql.DataFrame

val pair = noise1.map(line=>("+1"+line(0),line(1).toInt))
val df = pair.toDF("phone","noise")

val data = tmp1.join(df,Seq("phone"))

import org.apache.spark.sql.functions.udf

val plusone: String => String = "+1"+_
val plusudf = udf(plusone)

val cnt: String=>Int = _.count('$'==)
val udfcnt = udf(cnt)

val cas: String=>Int = _.toInt
val udfcast = udf(cas)

val san = spark.read.json("data1")
val sss = san.filter($"grade".isNotNull && $"SCORE".isNotNull).na.drop()
val sa = sss.select($"GRADE",$"Latitude",$"Longitude",$"PHONE",$"SCORE")
val ssr = sa.join(sss.groupBy($"PHONE").agg(min($"SCORE") as "ascore").withColumnRenamed("PHONE","aphone"),$"PHONE"===$"aphone" && $"SCORE" ===$"ascore").drop("aphone").drop("ascore")

val sani = ssr.withColumn("PHONE",plusudf($"PHONE"))

val colNames = Seq("grade","latitude","longitude","phone","score")
val sanit = sani.toDF(colNames:_*)

#val data3 = data.withColumn("price",udfcnt($"price"))

val result = data.join(sani, Seq("phone")).na.drop()
val output = result.drop($"id").drop($"score").filter($"image_url" =!= "")
output.repartition(1).write.mode("append").json("output.json")

scp -r dumbo:output.json .

linear regression:

https://www.programcreek.com/scala/org.apache.spark.ml.regression.LinearRegression
